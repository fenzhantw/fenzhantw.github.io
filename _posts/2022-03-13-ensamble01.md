---
title: "[BasicML] ê¸°ë³¸ ìŠ¤íƒœí‚¹ ì•™ìƒë¸”"
excerpt: "ê¸°ë³¸ì ì¸ ìŠ¤íƒœí‚¹Stackingì— ëŒ€í•œ ê°œë…ì„ ë°°ì›Œë³´ì"
categories:
    - BasicML

tag:
    - python
    - machine learning

author_profile: true    #ì‘ì„±ì í”„ë¡œí•„ ì¶œë ¥ ì—¬ë¶€

toc: true   #Table Of Contents ëª©ì°¨ 
toc_sticky: true
---

```
ì´ ë¬¸ì„œì— ë‚˜ì˜¤ëŠ” ìë£Œì™€ ë°ì´í„°ëŠ” ê¶Œì² ë¯¼ ì €ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ê°€ì´ë“œì™€ ì¸í”„ëŸ°ì˜ ê°•ì˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •ë¦¬í•˜ì˜€ìŠµë‹ˆë‹¤.
ì˜¤ë¥˜ë‚˜ í‹€ë¦° ë¶€ë¶„ì´ ìˆì„ ê²½ìš° ì–¸ì œë“ ì§€ ëŒ“ê¸€ í˜¹ì€ ë©”ì¼ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš” ğŸ˜„
```



###  ìŠ¤íƒœí‚¹ ì•™ìƒë¸”

- ìŠ¤íƒœí‚¹(Stacking)ì€ ê°œë³„ì ì¸ ì—¬ëŸ¬ ì•Œê³ ë¦¬ì¦˜ì—ì„œ ë‚˜ì˜¨ ì˜ˆì¸¡ ê²°ê³¼ê°’ì„ ìµœì¢…ì ì¸ ë©”íƒ€ ë°ì´í„° ì„¸íŠ¸ë¡œ ë§Œë“¤ì–´ ë³„ë„ì˜ MLì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í•™ìŠµì„ ìˆ˜í–‰í•˜ê³ , ì˜ˆì¸¡ì„ í•˜ëŠ” ë°©ë²•ì„.

*ë©”íƒ€ ëª¨ë¸: ê°œë³„ ëª¨ë¸ì˜ ì˜ˆì¸¡ëœ ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ì‹œ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ë°©ì‹ì„ ë©”íƒ€ ëª¨ë¸ì´ë¼ê³  í•¨

ì•„ë˜ ê·¸ë¦¼ì„ ë³´ì



ì¶œì²˜: íŒŒì´ì¬ ë¨¸ì‹ ëŸ¬ë‹ ì™„ë²½ ê°€ì´ë“œ

ê·¸ë¦¼ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë“¯ì´, ì›ë³¸ ë°ì´í„°ë¥¼ ë‹¤ì–‘í•œ ëª¨ë¸(ë¡œì§€ìŠ¤í‹± íšŒê·€, LightGBM ë“± ë“±)ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì˜ˆì¸¡í•˜ê³ , ê·¸ ê²°ê³¼ê°’ì„ ìŒ“ëŠ”ë‹¤. ê·¸ë¦¬ê³  ìŒ“ì¸ ê²°ê³¼ê°’(1,0)ì„ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ë°©ë²•ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

*ìœ„ì˜ ê·¸ë¦¼ì€ ê¸°ë³¸ì ì¸ ìŠ¤íƒœí‚¹ì„ ì„¤ëª…í•˜ê¸° ìœ„í•œ ë°©ë²•ì´ë¯€ë¡œ, ì‹¤ì œë¡œ ì´ë ‡ê²Œ í•´ë„ ë˜ëƒì— ëŒ€í•œ ëŒ€ë‹µì€ ì„¤ì™•ì„¤ë˜ê°€ ì¡´ì¬í•˜ê³  ìˆëŠ” í¸ì„.

#### Basic ìŠ¤íƒœí‚¹ ì‹¤ìŠµ ì½”ë“œ

```python
import numpy as np

from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

cancer_data = load_breast_cancer()

X_data = cancer_data.data
y_label = cancer_data.target

X_train , X_test , y_train , y_test = train_test_split(X_data , y_label , test_size=0.2 , random_state=0)
```

- ë‹¤ì–‘í•œ ë¶„ë¥˜ê¸° ëª¨ë“ˆì„ ë¶ˆëŸ¬ì˜¤ê³ , Train data setê³¼ Test data setìœ¼ë¡œ ë‚˜ëˆ”

```python
# ê°œë³„ ML ëª¨ë¸ì„ ìœ„í•œ Classifier ìƒì„±.
knn_clf  = KNeighborsClassifier(n_neighbors=4)
rf_clf = RandomForestClassifier(n_estimators=100, random_state=0)
dt_clf = DecisionTreeClassifier()
ada_clf = AdaBoostClassifier(n_estimators=100)

# ìµœì¢… Stacking ëª¨ë¸ì„ ìœ„í•œ Classifierìƒì„±. 
lr_final = LogisticRegression(C=10)

```

- ë¶„ë¥˜ê¸°ë¥¼ ê° ê°ì²´ì— í• ë‹¹

```python
# ê°œë³„ ëª¨ë¸ë“¤ì„ í•™ìŠµ. 
knn_clf.fit(X_train, y_train)
rf_clf.fit(X_train , y_train)
dt_clf.fit(X_train , y_train)
ada_clf.fit(X_train, y_train)

# í•™ìŠµëœ ê°œë³„ ëª¨ë¸ë“¤ì´ ê°ì ë°˜í™˜í•˜ëŠ” ì˜ˆì¸¡ ë°ì´í„° ì…‹ì„ ìƒì„±
knn_pred = knn_clf.predict(X_test)
rf_pred = rf_clf.predict(X_test)
dt_pred = dt_clf.predict(X_test)
ada_pred = ada_clf.predict(X_test)
```

- ëª¨ë¸ì„ í•™ìŠµí•˜ê³ , X_testë¥¼ í†µí•´ ì˜ˆì¸¡í•¨

```
 np.array([knn_pred, rf_pred, dt_pred, ada_pred])
```

- ë‹¤ìŒ ê°’ì„ í™•ì¸í•´ë³´ì

```
array([[0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,
        0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,
        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,
        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0,
        1, 0, 0, 1],
       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,
        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,
        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,
        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,
        1, 0, 0, 1],
       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,
        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1,
        0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,
        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,
        0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,
        1, 0, 0, 1],
       [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,
        1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1,
        1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0,
        0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1,
        0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0,
        1, 0, 0, 1]])
```

4ê°œì˜ ë¶„ë¥˜ê¸°ì—ì„œ ë‚˜ì˜¨ ì˜ˆì¸¡ê°’ë“¤ì´ knn_pred, rf_pred, dt_pred, ada_predì— ë‹´ê¸´ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. ì´ì œ ì´ëŸ¬í•œ ê²°ê³¼ê°’ì„ ë‹¤ì‹œ ì˜ˆì¸¡ ë°ì´í„°ë¡œ í™œìš©í•˜ê¸° ìœ„í•´ì„œ mxnì„ nxmìœ¼ë¡œ ë°”ê¿”ì¤„ í•„ìš”ê°€ ìˆë‹¤. ë”°ë¼ì„œ numpyì˜ transposeë¥¼ í†µí•´ ë°”ê¿”ë³´ì.

```python
pred = np.array([knn_pred, rf_pred, dt_pred, ada_pred])
print(pred.shape)

# transposeë¥¼ ì´ìš©í•´ í–‰ê³¼ ì—´ì˜ ìœ„ì¹˜ êµí™˜. ì»¬ëŸ¼ ë ˆë²¨ë¡œ ê° ì•Œê³ ë¦¬ì¦˜ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ í”¼ì²˜ë¡œ ë§Œë“¦. 
pred = np.transpose(pred)
print(pred.shape)
```

```
(4, 114)
(114, 4)
```

ë§ˆì§€ë§‰ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ë°ì´í„°ë¥¼ í†µí•´ ì˜ˆì¸¡ì„ í•´ë³´ì.

```
lr_final.fit(pred, y_test)
final = lr_final.predict(pred)

print('ìµœì¢… ë©”íƒ€ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„: {0:.4f}'.format(accuracy_score(y_test , final)))
```

ìµœì¢… ë©”íƒ€ ëª¨ë¸ì˜ ì˜ˆì¸¡ ì •í™•ë„: 0.9737

*ê¸°ë³¸ ìŠ¤íƒœí‚¹ ëª¨ë¸ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ ë§ˆì§€ë§‰ ëª¨ë¸ì¸ ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ ê¸°ë°˜ì—ì„œ í•™ìŠµí•  ë•Œ ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ë¡œ í•™ìŠµ ë°ì´í„°ê°€ ì•„ë‹Œ í…ŒìŠ¤íŠ¸ìš© ë ˆì´ë¸” ë°ì´í„° ì„¸íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•™ìŠµí–ˆê¸° ë•Œë¬¸ì— ê³¼ì í•© ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆìŒ.

ë”°ë¼ì„œ ë‹¤ìŒì— í¬ìŠ¤íŒ…í•  CV ì„¸íŠ¸ ê¸°ë°˜ì˜ ìŠ¤íƒœí‚¹ì€ ì´ëŸ¬í•œ ê³¼ì í•©ì— ëŒ€í•œ ê°œì„ ì„ ìœ„í•´ ê°œë³„ ëª¨ë¸ë“¤ì´ ê°ê° êµì°¨ ê²€ì¦ìœ¼ë¡œ ë©”íƒ€ ëª¨ë¸ì„ ìœ„í•œ í•™ìŠµìš© ìŠ¤íƒœí‚¹ ë°ì´í„° ìƒì„±ê³¼ ì˜ˆì¸¡ì„ ìœ„í•œ í…ŒìŠ¤íŠ¸ìš© ìŠ¤íƒœí‚¹ ë°ì´í„°ë¥¼ ìƒì„±í•œ ë’¤ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë©”íƒ€ ëª¨ë¸ì˜ í•™ìŠµê³¼ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•¨.





